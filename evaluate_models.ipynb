{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "def test_models_roc_auc_curve(\n",
    "    model_list: list,\n",
    "    X_y_dataframe,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    results_list = []\n",
    "    X, y = X_y_dataframe\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,\n",
    "                                                        random_state=random_state)\n",
    "    for mdl in model_list:\n",
    "\n",
    "        model = mdl.get('estimator')\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        model_name = mdl.get('model_name')\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred, average='micro')\n",
    "        recall = metrics.recall_score(y_test, y_pred, average='micro')\n",
    "        f1_score = metrics.f1_score(y_test, y_pred, average='micro')\n",
    "        # auc = metrics.roc_auc_score(y_test, y_pred, average='micro', multi_class='ovr', labels=pd.Categorical(y).unique())\n",
    "\n",
    "        results_list.append({\n",
    "                'model_name': model_name,\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1_score,\n",
    "                # 'roc_auc': auc,\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        results_list,\n",
    "        columns=['model_name', 'accuracy', 'precision',\n",
    "                 'recall', 'f1_score'],\n",
    "    )\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTANDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 8), (100000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('star_classification.csv')\n",
    "\n",
    "id_columns = ['obj_ID', 'run_ID', 'rerun_ID', 'cam_col',\n",
    "              'field_ID', 'spec_obj_ID', 'plate', 'MJD',\n",
    "              'fiber_ID']\n",
    "\n",
    "df = data.drop(columns=id_columns, axis=1)\n",
    "\n",
    "X = df.drop(columns=['class'], axis=1)\n",
    "y = df['class']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bopj\\AppData\\Local\\miniconda3\\envs\\ml-proj-rria\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_list = [\n",
    "    {\n",
    "        \"model_name\": \"Logistic Regression\",\n",
    "        \"estimator\": LogisticRegression(random_state=42),\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"Decision Tree\",\n",
    "        \"estimator\": DecisionTreeClassifier(random_state=42),\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"Random Forest\",\n",
    "        \"estimator\": RandomForestClassifier(random_state=42),\n",
    "    },\n",
    "]\n",
    "\n",
    "df_results = test_models_roc_auc_curve(model_list, (X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.85605</td>\n",
       "      <td>0.85605</td>\n",
       "      <td>0.85605</td>\n",
       "      <td>0.85605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.96485</td>\n",
       "      <td>0.96485</td>\n",
       "      <td>0.96485</td>\n",
       "      <td>0.96485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.97695</td>\n",
       "      <td>0.97695</td>\n",
       "      <td>0.97695</td>\n",
       "      <td>0.97695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  accuracy  precision   recall  f1_score\n",
       "0  Logistic Regression   0.85605    0.85605  0.85605   0.85605\n",
       "1        Decision Tree   0.96485    0.96485  0.96485   0.96485\n",
       "2        Random Forest   0.97695    0.97695  0.97695   0.97695"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-proj-rria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
